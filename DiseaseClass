# -*- coding: utf-8 -*-
"""Cassava_leaf_disease.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1n0W2m_ikKjYw4Dm3XXzWKhHMYN3yd8GD
"""

!pip install --upgrade --force-reinstall --no-deps kaggle

!mkdir /root/.kaggle
!pwd

"""Setup Kaggle credential to get access to the kaggle account to download the competition datasets

"""

!touch ~/.kaggle/kaggle.json

api_token ={"username":"jaspreetbhatia","key":"83f403b4cafb4780893a63cec15ad78a"}

import json

with open('/root/.kaggle/kaggle.json', 'w') as file:
    json.dump(api_token, file)

!chmod 600 ~/.kaggle/kaggle.json

!ls -lrt ~/.kaggle/kaggle.json

import kaggle

!mkdir cassava-leaf-disease-classification

!kaggle competitions download -c cassava-leaf-disease-classification

!kaggle competitions list

!ls -lrt

from zipfile import ZipFile
with ZipFile('/content/cassava-leaf-disease-classification.zip', 'r') as zipObj:
  # Extract all the contents of zip file in current directory
  zipObj.extractall('/content/cassava-leaf-disease-classification/')

!ls -lrt cassava-leaf-disease-classification/

RUNTIME = "COLLAB"

BASE_DIR = "/kaggle/input/cassava-leaf-disease-classification/"
TRAIN_DIR = "/kaggle/input/cassava-leaf-disease-classification/train_images/"
TEST_DIR = "/kaggle/input/cassava-leaf-disease-classification/test_images/"

if RUNTIME == "COLLAB":
  BASE_DIR = "/content/cassava-leaf-disease-classification/"
  TRAIN_DIR = "/content/cassava-leaf-disease-classification/train_images/"
  TEST_DIR = "/content/cassava-leaf-disease-classification/test_images/"

import numpy as np #linear algebra
import pandas as pd #data processing, CSV file I/O(e.g. pd.read_csv)
import os
import matplotlib.pyplot as plt
import json
import cv2 as cV
from PIL import Image

with open(os.path.join(BASE_DIR, "label_num_to_disease_map.json")) as file:
  map_classes = json.loads(file.read())

print(json.dumps(map_classes, indent=2))

label_list = [int(key) for key in map_classes.keys()]
label_list

input_files = os.listdir(os.path.join(BASE_DIR, "train_images"))
print(f"Number of train images: {len(input_files)}")

data_df = pd.read_csv(os.path.join(BASE_DIR, "train.csv"))
data_df.head(5)

data_df["class_name"] = data_df["label"].astype(str).map(map_classes)
data_df["label_str"] = data_df["label"].astype(str)
data_df.head(5)

data_df['class_name'].value_counts().plot(kind='bar')

data_df['class_name'].value_counts().plot(kind='bar')

"""Data is very imbalanced.So let us create a weight dictionary for the classes."""

from sklearn.utils import compute_class_weight
class_weight_array = compute_class_weight('balanced', label_list, data_df['label'])
class_weight_dict = dict()
for label,weight in zip(label_list, class_weight_array):
  class_weight_dict[label] = weight 
class_weight_dict

def viewImage(_image_path, _image_id):
  figure = plt.figure(figsize=(16,8))
  _image_path = os.path.join(_image_path, _image_id)
  img_data = Image.open(_image_path)
  plt.axis('off')
  plt.imshow(img_data)

def display_images_by_class(_class_name, _image_list):
  figure = plt.figure(figsize=(24,24))
  i=0
  for image_id in _image_list:
    _image_path = os.path.join(BASE_DIR, "train_images")
    _image_path = os.path.join(_image_path, image_id)
    img_data = Image.open(_image_path)
    plt.subplot(4, 4, i+1)
    plt.axis("off")
    plt.imshow(img_data, cmap = 'gray_r')
    plt.title(_class_name)
    i += 1

sample_image_dict = {}
for class_label in map_classes:
  # print(map_classes[class_label])
  _temp_image_list = data_df[data_df['label'] == int(class_label)].head(4)['image_id'].tolist()
  # print(_temp_image_list)
  sample_image_dict[map_classes[class_label]] = _temp_image_list
  display_images_by_class(map_classes[class_label], _temp_image_list)

IMG_HEIGHT = 400
IMG_WIDTH = 400
batch_size = 128

from albumentations import (
    Compose, HorizontalFlip, Flip, CLAHE, HueSaturationValue, CenterCrop, 
    RandomBrightness, RandomContrast, RandomGamma, Cutout,
    ToFloat, ShiftScaleRotate
)

AUGMENTATIONS_TRAIN = Compose([
    HorizontalFlip(p=0.5),
    Flip(always_apply=False, p=1.0),
    RandomContrast(limit=0.2, p=0.5)
    #RandomGamma(gamma_limit=(80, 120), p=0.5),
    RandomBrightness(limit=0.2, p=0.5),
    #HueSaturationValue(hue_shift_limit=5, sat_shift_limit=20, val_shift_limit=10, p=.9),
    #Cutout(always_apply=False, p=1.0, num_holes=28, max_h_size=8, max_w_size=8),
    CenterCrop(always_apply=False, p=1.0, height=IMG_HEIGHT, width=IMG_WIDTH),
    ShiftScaleRotate(always_apply=False, 
                     p=0.5, shift_limit=0, 
                     scale_limit=(0.5, 1.50), 
                     rotate_limit=15, 
                     interpolation=0, border_mode=0),
    #ShiftScaleRotate(
    #    shift_limit=0.0625, scale_limit=0.1, 
    #    rotate_limit=15, border_mode=cv2.BORDER_REFLECT_101, p=0.8), 
    ToFloat(max_value=255)
])

AUGMENTATIONS_TEST = Compose([
    ToFloat(max_value=255)
])

def display_augmented_images_by_class(_class_name, _image_list):
    
    i = 0
    for image_id in _image_list:
        figure = plt.figure(figsize=(24, 16))
        _image_path = os.path.join(BASE_DIR, "train_images")
        _image_path = os.path.join(_image_path, image_id)
        img_data = Image.open(_image_path)
        plt.subplot(4, 4, 1)
        plt.axis('off')
        plt.imshow(img_data, cmap='gray_r')
        plt.title("ORG :: " + _class_name)
        img_data = np.array(img_data.resize((IMG_HEIGHT, IMG_WIDTH), Image.ANTIALIAS))
        for img_count in range(2, 5):
            aug_img_data = AUGMENTATIONS_TRAIN(image=img_data)["image"]
            plt.subplot(4, 4, img_count)
            plt.axis('off')
            plt.imshow(aug_img_data, cmap='gray_r')
            plt.title("AUG :: " + _class_name)

for class_label in map_classes:
    _temp_image_list = data_df[data_df['label'] == int(class_label)].head(3)['image_id'].tolist()
    display_augmented_images_by_class(map_classes[class_label], _temp_image_list)

from sklearn.model_selection import train_test_split

train_images, validate_images, train_labels, validate_labels = train_test_split(data_df['image_id'], data_df['label'], test_size=0.20, random_state=42, stratify=data_df['label'])
print("Size of Training Set : ", train_images.shape)
print("Size of Training Label : ", train_labels.shape)
print("Size of Validation Set : ", validate_images.shape)
print("Size of Validation Label : ", validate_labels.shape)

train_data_size = train_images.shape[0]
validate_data_size = validate_images.shape[0]

IMG_HEIGHT = 400
IMG_WIDTH = 400
batch_size = 64

import tensorflow as tf

from tensorflow.python.keras.utils.data_utils import Sequence
import random

def load_single_image(data_type, image_id):
        if data_type == "TEST_DATA":
            image_path = os.path.join(TEST_DIR, image_id)
        else:
            image_path = os.path.join(TRAIN_DIR, image_id)
        img_data = Image.open(image_path)
        img_data = np.array(img_data.resize((IMG_HEIGHT, IMG_WIDTH), Image.ANTIALIAS))
        #print(img_data)
        return img_data
    
    
class AugmentedImageSequence(Sequence):
    def __init__(self, mode, data_set_type, x_set, y_set, batch_size, augmentations):
        self.mode = mode
        self.data_type = data_set_type
        self.x, self.y = x_set, y_set
        self.batch_size = batch_size
        self.augment = augmentations

    def __len__(self):
        return int(np.ceil(len(self.x) / float(self.batch_size)))

    
    def __getitem__(self, idx):
        batch_x = self.x[idx * self.batch_size:(idx + 1) * self.batch_size]
        
        if self.mode == "TEST":
            batch_y = []
        else:
            batch_y = self.y[idx * self.batch_size:(idx + 1) * self.batch_size]
        
        #print("length of Batch_X : {}".format(len(batch_x)))
        img_list = []
        for x in batch_x:
            if self.data_type == "TRAIN_DATA":
                random_num = random.uniform(0, 1)
                if random_num > 0.5:
                    img_data = self.augment(image=load_single_image(self.data_type, x))["image"]
                else:
                    img_data = load_single_image(self.data_type, x)
            else:
                img_data = load_single_image(self.data_type, x)
            
            img_list.append(img_data)
        
        #print("length of img_list : {}".format(len(img_list)))
        img_array = np.stack([img_data for img_data in img_list], axis=0)
        
        return img_array, np.array(batch_y)

train_gen = AugmentedImageSequence("TRAIN", "TRAIN_DATA", train_images, train_labels, batch_size, augmentations=AUGMENTATIONS_TRAIN)
valid_gen = AugmentedImageSequence("TRAIN", "VALIDATE_DATA", validate_images, validate_labels, batch_size, augmentations=AUGMENTATIONS_TEST)

from tensorflow.keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Flatten, Dense, Dropout, InputLayer
from tensorflow.keras.layers import BatchNormalization, Activation
from tensorflow.keras.models import Model, Sequential
from tensorflow.keras.optimizers import RMSprop
from tensorflow.keras.applications import InceptionV3

if RUNTIME == "COLLAB":
  trained_model = InceptionV3(include_top = False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))
else:
  trained_model = InceptionV3(include_top = False, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3),
              weights="../input/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5")
  
trained_model.summary()

trained_model.trainable = True # Freeze InceptionV3 base
model = Sequential()
model.add(trained_model)
model.add(GlobalAveragePooling2D())
model.add(Flatten()) 
model.add(Dense(512 , activation = "relu")) #Added New
model.add(Dropout(0.5)) #Updated DropOut from 0.3 to 0.5
#model.add(Dense(512 , activation = "relu"))
model.add(Dense(units = 5 , activation = "softmax"))
model.summary()

from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau
from tensorflow.keras import optimizers

earlystop = EarlyStopping(monitor = 'val_acc', min_delta = 1e-4, patience = 5, mode = 'max', 
                      restore_best_weights = True, verbose = 0)
learning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', 
                                            patience=3, 
                                            verbose=1, 
                                            factor=0.5, 
                                            min_lr=0.00001)
mcp_save = ModelCheckpoint('Cassava_Best_Model_InceptionV3_V06.hdf5', 
                           save_best_only=True, monitor='val_loss', mode='min')
custom_callbacks = [earlystop, mcp_save, learning_rate_reduction]
print(custom_callbacks)

model.compile(loss='sparse_categorical_crossentropy', optimizer=optimizers.RMSprop(lr=1e-5), metrics=['acc'])
history = model.fit(
    train_gen, 
    epochs=20,
    validation_data=valid_gen,
    validation_steps=validate_data_size//batch_size,
    steps_per_epoch=train_data_size//batch_size,
    callbacks=custom_callbacks,
    class_weight=class_weight_dict
)

#003 - GlobalAveragePooling and Flattern, Dropout - 0.3
#Model with GlobalAveragePooling, no Flattern, Dropout - 0.5
#003 - GlobalAveragePooling and Flattern, Dropout - 0.5, test_split - 0.20
model.save("Cassava_InceptionV3_V005.h5")
pd.DataFrame(history.history).plot(figsize=(8, 5))
plt.grid(True)
plt.gca().set_ylim(0, 1) # setting limits for y-axis
plt.show()
tf.keras.backend.clear_session() # clearing session
np.random.seed(42) # generating random see
tf.random.set_seed(42) # set.seed function helps reuse same set of random variables
